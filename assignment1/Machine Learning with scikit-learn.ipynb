{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Pandas recap\n","\n","Recall that Pandas is a Python library used to handle datasets, in a spreadsheet like manner, using \"DataFrame\" objects.  \n","[See the site used for exercise 1](https://www.w3resource.com/python-exercises/pandas/index.php) for some useful Pandas commands.\n","![Pandas DataFrames](pandas-data-structure.svg)"]},{"cell_type":"markdown","metadata":{},"source":["Having the Pandas documentation nearby is useful, especially the DataFrame page: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import pandas (and optionally numpy) using shorthand alias\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["Create a example DataFrame using a Python dictionary (data type) with 4 columns and 10 rows"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["example_dict = {\n","    'name':     ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n","    'score':    [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n","    'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n","    'qualify':  ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']\n","    }\n","\n","# Create DataFrame using above data\n","df = pd.DataFrame(example_dict)\n","# Print df\n","df"]},{"cell_type":"markdown","metadata":{},"source":["Display only first and last column of your DataFrame "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Index dataframe using indices. Syntax:\n","# [<row id(s)>, <column id(s)]\n","# Select all rows       --> :\n","# Select column 0 and 3 --> [0,3]\n","df.iloc[:, [0,3]]\n","\n","# Alternative using column names instead of indices:\n","# df.loc[:, ['name', 'qualify']]"]},{"cell_type":"markdown","metadata":{},"source":["# Machine Learning with scikit-learn\n","Now, let's move on how to do machine learning using the sklearn python library. We will be using covid data for USA, trying to predict the number of deaths only knowing the number of cases (and later also state.)\n","\n","Contents:\n","* What is Machine Learning?\n","  * Types of Machine Learning\n","* Train-Test split\n","* Use `sklearn` to build linear regression model*\n","* One-Hot Encoding\n","* Pipelines\n","* Evaluation Metrics\n","\n","\n","**Disclaimer: Linear regression is not the most suitable algorithm for this dataset, but we are using it to illustrate how to use scikit-learn*"]},{"cell_type":"markdown","metadata":{},"source":["## What is Machine Learning?\n","\n","If you have had little experience with Machine Learning before, refer to chapter 1 and 2 of todays reading. In short:\n","\n","* Learning patterns in your data without being explicitly programmed\n","* A function that maps features to an output\n","\n","<img src=\"https://brookewenig.com/img/DL/al_ml_dl.png\" style=\"height: 350px; padding: 10px\"/>"]},{"cell_type":"markdown","metadata":{},"source":["## 3 Types of Machine Learning and their subtypes\n","* Supervised Learning\n","  * Regression <img src=\"https://miro.medium.com/max/640/1*LEmBCYAttxS6uI6rEyPLMQ.png\" style=\"height: 150px; padding: 10px\"/>\n","  * Classification\n","    <img src=\"https://cdn3-www.dogtime.com/assets/uploads/2018/10/puppies-cover.jpg\" style=\"height: 150px; padding: 10px\"/>\n","    <img src=\"https://images.unsplash.com/photo-1529778873920-4da4926a72c2?ixlib=rb-1.2.1&w=1000&q=80\" style=\"height: 150px; padding: 10px\"/>\n","* Unsupervised Learning\n","<img src=\"https://www.iotforall.com/wp-content/uploads/2018/01/Screen-Shot-2018-01-17-at-8.10.14-PM.png\" style=\"height: 150px; padding: 10px\"/>\n","* Reinforcement Learning\n","<img src=\"https://brookewenig.com/img/ReinforcementLearning/Rl_agent.png\" style=\"height: 150px; padding: 10px\"/>"]},{"cell_type":"markdown","metadata":{},"source":["We will be referencing the [scikit-learn docs](https://scikit-learn.org/stable/user_guide.html) and [pandas docs](https://pandas.pydata.org/pandas-docs/stable/index.html) where relevant, and will be analyzing data from the New York Times COVID-19 US States dataset from https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"]},{"cell_type":"markdown","metadata":{},"source":["Today we're going to start simple and focus on a supervised learning (regression) problem. Here we will use a linear regression model to predict the number of deaths resulting from COVID-19."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load csv directly from the internet\n","# Overwrite previous defined 'df' variable\n","df = pd.read_csv(\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv\")\n","df\n"]},{"cell_type":"markdown","metadata":{},"source":["We see the first and last 5 rows of the dataframe above. For instance, on 2020-01-21 there was 1 case and 0 deaths in the state Washington (and FIPS state codes not relevant).\n","\n","We check the amount of rows/columns in dataframe:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Relationship between Cases & Deaths\n","\n","Lets make a scatterplot for each state along with its 2 variables: Cases and covid deaths in the state."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter to 2020-05-01\n","# Use dataframe mask to do so. First get the date column, then make a condition:\n","mask_05_01 = df[\"date\"] == \"2020-05-01\"\n","df_05_01 = df[mask_05_01]\n","\n","# Create an Axes object using Matplotlib indirectly\n","# Matplotlib naming explained: https://www.machinelearningplus.com/wp-content/uploads/2019/01/99_matplotlib_structure.png\n","ax = df_05_01.plot(x=\"cases\", y=\"deaths\", kind=\"scatter\",\n","                   figsize=(12,8), s=100, title=\"Deaths vs Cases on 2020-05-01 - All States\")\n","\n","# Set labels for each point:\n","# Iterate over all rows, getting index and (column names)\n","# (cases, deaths, state) pass this tuple to the ax.text function to set observation labels\n","for index, (cases, deaths, state) in df_05_01[[\"cases\", \"deaths\", \"state\"]].iterrows():\n","\n","    # Set text for every (x,y) point in plot (cases, deaths) using \"state\" as text\n","    ax.text(cases, deaths, state)"]},{"cell_type":"markdown","metadata":{},"source":["## New York & New Jersey are Outliers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter to states that are NOT New York and NOT New Jersey\n","mask_not_ny_nj = (df[\"state\"] != \"New York\") & (df[\"state\"] != \"New Jersey\") \n","\n","# Filter out unwanted rows using mask\n","not_ny = df[ mask_not_ny_nj ]\n","\n","# Display first 5 rows\n","not_ny.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Filter to 2020-05-01\n","mask_not_ny_05_01 = not_ny[\"date\"] == \"2020-05-01\"\n","not_ny_05_01 = not_ny[ mask_not_ny_05_01 ]\n","\n","# Create an Axes object using Matplotlib indirectly\n","# Matplotlib naming explained: https://www.machinelearningplus.com/wp-content/uploads/2019/01/99_matplotlib_structure.png\n","ax = not_ny_05_01.plot(x=\"cases\", y=\"deaths\", kind=\"scatter\", \n","                   figsize=(12,8), s=50, title=\"Deaths vs Cases on 2020-05-01 - All States but NY and NJ\")\n","\n","# Iterate over all rows, getting index and (column names)\n","# (cases, deaths, state) pass this tuple to the ax.text function to set observation labels\n","for index, (cases, deaths, state) in not_ny_05_01[[\"cases\", \"deaths\", \"state\"]].iterrows():\n","\n","    # Set text for every (x,y) point in plot (cases, deaths) using \"state\" as text\n","    ax.text(cases, deaths, state)"]},{"cell_type":"markdown","metadata":{},"source":["## New York versus California COVID-19 deaths comparison\n","Lets plot how these 2 states # of deaths change through time with a lineplot. Lets first use a mask (filter) to only get the two states:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Mask with boolean condition again\n","mask_ny_cali = (df[\"state\"] == \"New York\") | (df[\"state\"] == \"California\") \n","df_ny_cali = df[ mask_ny_cali ]\n","\n","# Get last observations\n","df_ny_cali.tail()"]},{"cell_type":"markdown","metadata":{},"source":["Does not look like its easy to make a plot when the dataframe has this structure. We need a structure like this:  \n","\n","    date    \tCalifornia\tNew York  \n","    2022-08-30\t94973.0\t       70374.0\n","\n","That would make it easy to plot the change over time. To do that, let's \"pivot\" our df_ny_cali DataFrame so that we can plot deaths over time for both states:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_ny_cali_pivot = df_ny_cali.pivot(index='date', columns='state', values='deaths')\n","\n","# Fill missing calues with 0\n","df_ny_cali_pivot = df_ny_cali_pivot.fillna(0)\n","df_ny_cali_pivot"]},{"cell_type":"markdown","metadata":{},"source":["Voil√†! Now we are ready to plot:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_ny_cali_pivot.plot(kind='line',\n","                    title=\"Deaths 2020-01-25 to 2020-05-01 - CA and NY\",\n","                    figsize=(12,8))"]},{"cell_type":"markdown","metadata":{},"source":["## Train-Test Split (aka Train-Dev split, aka Train-Validation split)\n","First we need to prepare our dataset before we go into linear regression.  \n","*For more information on this, see page 51 in  Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems.*  \n","Basically, we set aside a part of out dataset that is use to see how good our model is. \n","\n","![](https://brookewenig.com/img/IntroML/trainTest.png)"]},{"cell_type":"markdown","metadata":{},"source":["Often, you would select a random part of the data as the test set.  \n","Because this is temporal data, instead of doing a random split, we will use data from March 1 to April 7 to train our model, and test our model by predicting values for April 8 - 14.\n","\n","Apart from splitting the data into training data and test data, we also split the training data in 2 different Pandas DataFrames:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df = df[(df[\"date\"] >= \"2020-03-01\") & (df[\"date\"] <= \"2020-04-07\")]\n","test_df = df[df[\"date\"] > \"2020-04-07\"]\n","\n","# Create 2 dataframes for our training data\n","X_train = train_df[[\"cases\"]]   # 1 feature\n","y_train = train_df[\"deaths\"]    # target label to predict\n","\n","# Create 2 dataframes for our test data\n","X_test = test_df[[\"cases\"]]\n","y_test = test_df[\"deaths\"]"]},{"cell_type":"markdown","metadata":{},"source":["Lets investigate what the dataframes contain:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_train.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["## Linear Regression\n","If we know the number of cases on a given day, can we predict the number of deaths?  \n","Let's build a Linear regression *model*, to do that. It finds a linear relationship between deaths and covid cases. Is it true that more cases -> more deaths?  We will see.   \n","* Goal: Find a line that best fits our set of datapoints. Equation for line:\n","$$\\hat{y} = w_0 + w_1x$$\n","\n","\n","$${y} \\approx \\hat{y} + \\epsilon $$\n","* *x*: feature (cases)\n","* *y*: label (deaths)\n","\n","For example, here's some random data in a scatterplot, where 'x' is used to predict 'y' by reading off the position on the line: \n","\n","![](https://miro.medium.com/max/640/1*LEmBCYAttxS6uI6rEyPLMQ.png)"]},{"cell_type":"markdown","metadata":{},"source":["Here we will be fitting a [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) model from the scikit-learn python library."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","# Create a LinearRegression object \n","lr_model = LinearRegression()\n","\n","# Fit (train) the model by giving it the training data\n","# (It learns the relationship between X and y)\n","lr_model.fit(X_train, y_train)\n","\n","print('The equation to calculate the # of deaths:')\n","print(f\"deaths = {lr_model.intercept_:.4f} + {lr_model.coef_[0]:.4f}*cases\")"]},{"cell_type":"markdown","metadata":{},"source":["This is our linear regression model, than can be used to predict the number of deaths, using the number of cases.  \n","What happens if we have 0 cases? How many deaths would that equal?  \n","Hmmm... if we have no cases, then there should be no deaths caused by COVID-19, so let's set the intercept to be 0."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Set intercept to 0 with fit_intercept=False\n","lr_model = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n","print(f\"deaths = {lr_model.coef_[0]:.4f}*cases\")"]},{"cell_type":"markdown","metadata":{},"source":["So this model tells us the mortality rate. But we know that some states have higher mortality rates than others.   \n","Right now we only used 1 feature (cases) to predict the number of deaths. Let's also include the state as a feature!"]},{"cell_type":"markdown","metadata":{},"source":["## One-Hot Encoding\n","How do we handle non-numeric features, such as the state?  \n","Imagine if we only used *state* as a feature. Maybe the model would look like this:  \n","$$deaths = 0.0355*state$$\n","\n","But! We cannot multiply using the state, eg \"Washington\", since it is a categorical feature.\n","\n","One idea is to map each state to a number. For example:\n","  * 'New York' = 1, 'California' = 2, 'Louisiana' = 3\n","  \n","BUT this implies $$New\\ York*2 = California$$\n","\n","Better idea:\n","* Create a ‚Äòdummy‚Äô feature for each category (state)\n","* 'New York' => [1, 0, 0], 'California' => [0, 1, 0], 'Louisiana' => [0, 0, 1]\n","\n","This technique is known as [\"One Hot Encoding\"](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder\n","\n","X_train = train_df[[\"cases\", \"state\"]]\n","X_test = test_df[[\"cases\", \"state\"]]\n","\n","enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n","\n","# Encode all columns in the training data:\n","encoded_states = enc.fit(X_train).transform(X_train)"]},{"cell_type":"markdown","metadata":{},"source":["Let's check the shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Before transforming we had\", X_train.shape[0], \"rows (observations) and\", X_train.shape[1], \"columns\")\n","print(\"After transforming using one hot encoding we have\", encoded_states.shape[0], \"rows (observations) and\", encoded_states.shape[1], \"columns\")"]},{"cell_type":"markdown","metadata":{},"source":["Yikes way too many columns now! It one-hot encoded the (numerical) cases variable too. We only wanted to encode the categorical feature (states)"]},{"cell_type":"markdown","metadata":{},"source":["We need sklearn's [column transformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) to only apply the one hot encoding to a single column.  \n","In Sklearn, the One Hot encoder `enc` we created above is called a transformer, since it has a `transform` method.\n","\n","**Useful Sklearn jargon definitions:**  \n","*estimator(s)*: An object which manages the estimation and decoding of a model. Estimators must provide a fit method, and should provide set_params and get_params, although these are usually provided by inheritance from base.BaseEstimator.\n","\n","*transformers*: An estimator supporting transform and/or fit_transform.\n","\n","*predictor(s)*:\n","An estimator supporting predict and/or fit_predict. This encompasses classifier, regressor, outlier detector and clusterer.\n","Not to be confused with: In statistics, ‚Äúpredictors‚Äù refers to features.\n","\n","*regressor(s)*:\n","A supervised (or semi-supervised) predictor with continuous output values.  \n","Regressors usually inherit from base. RegressorMixin, which sets their _estimator_type attribute.  \n","A regressor can be distinguished from other estimators with is_regressor.\n","\n","A regressor must implement:\n","* fit\n","* predict\n","* score\n","\n","See above and more with links on: https://scikit-learn.org/stable/glossary.html\n","\n","We transform only the \"state\" column in X_train :"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","\n","ct = ColumnTransformer([(\"encoder transformer\", enc, [\"state\"])], remainder=\"passthrough\")\n","\n","# Print the result of the above transformation nicely using pandas:\n","pd.DataFrame(ct.fit_transform(X_train), dtype=int)"]},{"cell_type":"markdown","metadata":{},"source":["Before we had 2 columns in X_train; cases and state.  \n","How many features (columns) do we have now? 55+1! Whats the 55 new ones? They are basically a vector of zeroes along with a single 1 for every state. Let's verify that by printing how many states we have in the *training* dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"There's\", len( X_train['state'].unique() ), \"unique states in the training dataset\")"]},{"cell_type":"markdown","metadata":{},"source":["So for every state, we have a new column. Let's use these columns for build a even better linear regression model that takes state and cases into account when predicting the number of deaths."]},{"cell_type":"markdown","metadata":{},"source":["## Pipelines\n","\n","We combine the data transformation step we did above with the linear model we created earlier in a \"pipeline\". Data \"flows\" from top to bottom. The beauty of pipelines is the modularity and clarity for the whole data science process.    \n","We can chain together a series of data transformations with a [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). This way we also ensure that whatever operations we apply to our training set, we also apply in the same order to our test set."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","\n","# Define the pipeline steps. \n","pipeline = Pipeline(steps=[\n","                            (\"ct\", ct),         # step 1 in pipeline: Transform the columns we specified above (onehote encode state)\n","                            (\"lr\", lr_model)    # step 2 in pipeline: Fit the linear model using the transformed data\n","                        ])\n","\n","\n","pipeline_model = pipeline.fit(X_train, y_train)\n","\n","y_pred = pipeline_model.predict(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["We now have a new model that contains a coefficient for each column.  \n","Thus when calculating the number of deaths, the model can use the coeffient as a \"weight\" of how important the state is. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get step 1 in the pipline (lr_model object) in the pipeline, then the 1'th element of the tuple, then the coef_ attribute for the LinearModel object. \n","print(\"Our linear model contains\", len(pipeline_model.steps[1][1].coef_), \"coefficients\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Try to print these one at a time to understand above code:\n","# print(pipeline_model.steps[1])\n","# print(pipeline_model.steps[1][1])\n","# print(pipeline_model.steps[1][1].coef_)"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation Metrics\n","To measure how good our regression model is, we can use the following metrics:\n","\n","<img src=\"https://brookewenig.com/img/IntroML/RMSE.png\" style=\"height: 150px; padding: 10px\"/>"]},{"cell_type":"markdown","metadata":{},"source":["So how \"good\" is our regression model?  \n","Let's compute the MSE and RMSE for our test dataset using the [sklearn.metrics](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html?highlight=mean_squared_error).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","import numpy as np\n","\n","mse = mean_squared_error(y_test, y_pred)\n","rmse = np.sqrt(mse)\n","print(f\"MSE is {mse:.1f}, RMSE is {rmse:.1f}\")"]},{"cell_type":"markdown","metadata":{},"source":["The lower the error the better. If we had spend time on optimizing our model, we could perhaps lower the error."]},{"cell_type":"markdown","metadata":{},"source":["## Compare Predictions\n","\n","It is difficult to say if this is a \"good\" model or not. Let's also judge it by some example predictions. We show the test dataset's true deaths and compare it to what the linear model predicted. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Concatenate the test dataset (what we hope to predict as close as possible) with the predictions made by our model:\n","pred = pd.concat([ \n","                    test_df.reset_index(drop=True), \n","                    pd.DataFrame(y_pred, columns=[\"predicted_deaths\"])\n","                ], axis=1)\n","pred"]},{"cell_type":"markdown","metadata":{},"source":["Voila! You have successfully built a machine learning pipeline using scikit-learn!\n","\n","This tutorial was based on https://github.com/databricks/tech-talks/blob/master/2020-04-22%20%7C%20Machine%20Learning%20with%20scikit-learn/Machine%20Learning%20with%20scikit-learn.ipynb"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.11"},"name":"Machine Learning with scikit-learn","notebookId":1542346951515009,"vscode":{"interpreter":{"hash":"36d97a4d4bea7d9a85534fa8b4ddf8b5e242ed69f2b8f72e295a68b07e2f8bc3"}}},"nbformat":4,"nbformat_minor":0}
